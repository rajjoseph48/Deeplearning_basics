{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_classification_using_Keras_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajjoseph48/Deeplearning_basics/blob/DL-using-Keras/mnist_classification_using_Keras_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL_IazKUjjMO",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning using Keras\n",
        "## MNIST Digit Classification using CNN "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMFo0NVJk9Rt",
        "colab_type": "text"
      },
      "source": [
        "### Install Tensorflow-gpu 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsStMe17k9Gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! pip install tensorflow-gpu==2.0.0-beta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4ZpEx8llbfa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "59f490c4-33b8-456e-e344-eebc4675642a"
      },
      "source": [
        "! python --version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrNvoKLtks6c",
        "colab_type": "text"
      },
      "source": [
        "### Load Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvo5ep-6ji6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "429566a0-7175-4461-f308-bb801ba4d719"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "#import tensorflow.keras as keras"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDWoQxslitmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense, Dropout, Softmax, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqFOOpCFm76U",
        "colab_type": "text"
      },
      "source": [
        "### Load Dataset and preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqCEzauym6ll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxERr1pvnIj0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "8e135762-c8d4-4bcb-af1c-5199f37270b1"
      },
      "source": [
        "print('x_train shape: ', x_train.shape)\n",
        "print('y_train shape: ', y_train.shape)\n",
        "print('x_test shape: ', x_test.shape)\n",
        "print('y_test shape: ', y_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape:  (60000, 28, 28)\n",
            "y_train shape:  (60000,)\n",
            "x_test shape:  (10000, 28, 28)\n",
            "y_test shape:  (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KGaSISYnt_R",
        "colab_type": "text"
      },
      "source": [
        "**We have 60000 training data and 10000 test data. x_train and x_test contains the pixel intensity values in monochrome ranging from 0 to 255.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yluiS0UJoTuE",
        "colab_type": "text"
      },
      "source": [
        "#### Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXoQfAcFHb1k",
        "colab_type": "text"
      },
      "source": [
        "The values of the pixel intensities are in range from 0 to 255. These values are normalized to be in a range from 0 to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38wy4jrunpkD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "080a292f-f40e-4561-a685-b61610775dbf"
      },
      "source": [
        "print('Initial max value in training set: ', x_train.max())\n",
        "print('Initial max value in test set: ', x_test.max())\n",
        "\n",
        "x_train, x_test = x_train/x_train.max(), x_test/x_test.max()\n",
        "\n",
        "print('Max value in training set after normalization: ', x_train.max())\n",
        "print('Max value in test set after normalization: ', x_test.max())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial max value in training set:  255\n",
            "Initial max value in test set:  255\n",
            "Max value in training set after normalization:  1.0\n",
            "Max value in test set after normalization:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWmeAF4vHI2Q",
        "colab_type": "text"
      },
      "source": [
        "Labels which are numbers from 0 to 10 is One Hot Encoded to form 1D array of 10 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6ImckmYGdnT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7f618054-77c4-4fe4-aaea-258b4fdf0fdc"
      },
      "source": [
        "n_classes = 10\n",
        "y_train, y_test = to_categorical(y_train,n_classes), to_categorical(y_test, n_classes)\n",
        "print(y_train[0])\n",
        "print(y_test[0])\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h8gxcBWGtYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(60000,28,28,1).astype('float32')\n",
        "x_test = x_test.reshape(10000,28,28,1).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxIuR0UuO-J5",
        "colab_type": "text"
      },
      "source": [
        "#### Building CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAevlMDbO9cF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "outputId": "5342d572-8f4b-429e-ecfb-9babb930d047"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# First Conv-Maxpool layer\n",
        "model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(28,28,1)))\n",
        "model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
        "model.add(Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Secoond Conv-Maxpool layer\n",
        "model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(28,28,1)))\n",
        "model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
        "model.add(Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# First Dense layer\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation='tanh'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Second Dense Layer and output layer\n",
        "\n",
        "#model.add(Dense(64,activation='relu'))\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "# Third Dense Layer and output layer\n",
        "model.add(Dense(64,activation='tanh'))\n",
        "model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "# Model Summary\n",
        "model.summary()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 22, 22, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 9, 9, 32)          36896     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 5, 5, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 296,490\n",
            "Trainable params: 296,490\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90gGJUVNWlwx",
        "colab_type": "text"
      },
      "source": [
        "Configure the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQkB3VlySBhF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',loss = 'categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzTfGMqxW4ku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8a46d475-cc62-4184-f2c2-a60e49aa0975"
      },
      "source": [
        "model.fit(x_train,y_train,batch_size=256,epochs=50,verbose=1,validation_data=(x_test,y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 20s 340us/sample - loss: 0.3828 - accuracy: 0.8822 - val_loss: 0.0566 - val_accuracy: 0.9820\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 18s 304us/sample - loss: 0.0823 - accuracy: 0.9761 - val_loss: 0.0366 - val_accuracy: 0.9886\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 18s 306us/sample - loss: 0.0603 - accuracy: 0.9827 - val_loss: 0.0376 - val_accuracy: 0.9889\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 18s 303us/sample - loss: 0.0461 - accuracy: 0.9867 - val_loss: 0.0278 - val_accuracy: 0.9917\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 18s 302us/sample - loss: 0.0407 - accuracy: 0.9878 - val_loss: 0.0273 - val_accuracy: 0.9926\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 18s 304us/sample - loss: 0.0354 - accuracy: 0.9896 - val_loss: 0.0251 - val_accuracy: 0.9923\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 18s 307us/sample - loss: 0.0290 - accuracy: 0.9915 - val_loss: 0.0241 - val_accuracy: 0.9926\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 18s 302us/sample - loss: 0.0288 - accuracy: 0.9913 - val_loss: 0.0255 - val_accuracy: 0.9926\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 18s 302us/sample - loss: 0.0243 - accuracy: 0.9927 - val_loss: 0.0238 - val_accuracy: 0.9937\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 18s 303us/sample - loss: 0.0229 - accuracy: 0.9931 - val_loss: 0.0319 - val_accuracy: 0.9926\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 18s 303us/sample - loss: 0.0251 - accuracy: 0.9924 - val_loss: 0.0277 - val_accuracy: 0.9930\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 18s 300us/sample - loss: 0.0204 - accuracy: 0.9940 - val_loss: 0.0262 - val_accuracy: 0.9932\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 18s 302us/sample - loss: 0.0189 - accuracy: 0.9944 - val_loss: 0.0263 - val_accuracy: 0.9930\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 18s 302us/sample - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0246 - val_accuracy: 0.9943\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 18s 305us/sample - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.0269 - val_accuracy: 0.9933\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 18s 300us/sample - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.0259 - val_accuracy: 0.9933\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 18s 302us/sample - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.0256 - val_accuracy: 0.9948\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 18s 300us/sample - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0274 - val_accuracy: 0.9931\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 18s 303us/sample - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.0269 - val_accuracy: 0.9937\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 18s 302us/sample - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.0250 - val_accuracy: 0.9940\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 18s 303us/sample - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.0268 - val_accuracy: 0.9935\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 18s 302us/sample - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.0247 - val_accuracy: 0.9939\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 18s 305us/sample - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.0254 - val_accuracy: 0.9944\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 18s 303us/sample - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.0215 - val_accuracy: 0.9947\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 18s 303us/sample - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.0235 - val_accuracy: 0.9943\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 18s 302us/sample - loss: 0.0127 - accuracy: 0.9965 - val_loss: 0.0219 - val_accuracy: 0.9945\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 18s 305us/sample - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.0244 - val_accuracy: 0.9946\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 18s 303us/sample - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.0240 - val_accuracy: 0.9946\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 18s 302us/sample - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.0295 - val_accuracy: 0.9937\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 18s 302us/sample - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.0291 - val_accuracy: 0.9934\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 18s 304us/sample - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.0217 - val_accuracy: 0.9958\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 18s 301us/sample - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.0253 - val_accuracy: 0.9943\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 18s 301us/sample - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.0271 - val_accuracy: 0.9948\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 18s 302us/sample - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.0261 - val_accuracy: 0.9945\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 18s 305us/sample - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.0246 - val_accuracy: 0.9945\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 18s 301us/sample - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0285 - val_accuracy: 0.9946\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 18s 302us/sample - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.0284 - val_accuracy: 0.9937\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 18s 303us/sample - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.0250 - val_accuracy: 0.9947\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 18s 304us/sample - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.0265 - val_accuracy: 0.9944\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 18s 302us/sample - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0250 - val_accuracy: 0.9947\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 18s 301us/sample - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0247 - val_accuracy: 0.9947\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 18s 303us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0292 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 18s 303us/sample - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.0290 - val_accuracy: 0.9947\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 18s 302us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0291 - val_accuracy: 0.9932\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 18s 301us/sample - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.0242 - val_accuracy: 0.9951\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 18s 302us/sample - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.0258 - val_accuracy: 0.9938\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 18s 303us/sample - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0263 - val_accuracy: 0.9948\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 18s 302us/sample - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0335 - val_accuracy: 0.9932\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 18s 301us/sample - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.0293 - val_accuracy: 0.9944\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 18s 302us/sample - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0306 - val_accuracy: 0.9943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f60e059a5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycZopTrCXL-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}